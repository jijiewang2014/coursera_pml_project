---
title: " Predict the Quality of Weight Lifting with Machine Learning"

output:
  html_document:
    keep_md: true

---

##Synopsis
The goal of this project is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict of the quality of their weight lifting form. We applied random forest tree algorithsm, and achieved an out-of-sample error rate of 10%.

Source of the dataset: Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013. 

```{r load_library,results='hide'}
library(plyr)
library(dplyr)
library(caret)
library(ggplot2)
```
##Data Loading and Cleaning

Data are read from csv file into a dataframe. In the quiz data (20 cases), some columns have many NA values, and thus cannot be used to build prediction model. We eliminated those columns. Additonally, we eliminated all the columns that are not data on weight lifting except user_name and num, which are needed for futher processing. 

``` {r load_clean_data}
training<-read.csv("pml-training.csv", header=TRUE) #read training data
quizdata<-read.csv("pml-testing.csv", header=TRUE) # read quiz data

# Retain columns that are not NA in the quiz dataset
col_complete<-!is.na(quizdata[1,])
training<-training[,col_complete]
quizdata<-quizdata[,col_complete]


# Also remove columns 1 and 3:6 because these are not relavant to weight lifting.
training<-training[,-c(1,3:6)]
quizdata<-quizdata[,-c(1,3:6)]
```

##Data Patition and Processing
In order to build the model. We first partitioned the data into two sets, 85% as training data and 15% as testing data for cross validation purpose. For each time window, we calculated the averages for all the column except "classe","user_name", and "num_window". After this step, user_name and num_window columns are removed. In the end, the data contains only  "classe" column and the columns are related to weight lifting, and each row is the average data for one time window.

```{r partition_process_data}

# Separate into training and testing data set.
inTrain <- createDataPartition(y=training$num_window, p=0.85, list=FALSE)
trn_in_training <- training[inTrain,]
tst_in_training <- training[-inTrain,]

# Calculate mean for all columns foreach num_window.
train_usr_win_mean <- ddply(trn_in_training, .(user_name, num_window, classe), numcolwise(mean))

# Further remove columns user_name and num_window.
trn_train_usr_win_mean<-train_usr_win_mean[,-(1:2)]
tst_train_usr_win_mean<-tst_in_training[,-(1:2)]
quizdata<-quizdata[,-(1:2)]
```
##Model building
We applied random forest algorithsm to predict the "classe" variable. We chose random forest because it is a fairly accurate algorishm for classification problem

```{r build_model}
modFit<-train(classe ~ ., data=trn_train_usr_win_mean,method="rf",trControl=trainControl(method="cv",number=5),prox=TRUE,allowParallel=TRUE)
modFit
```

```{r train_model}

plot(modFit$finalModel,main="Classification Tree")

```

## Cross Validation
We then applied the model to the testing data to conduct cross validation. the confusionMatrix is as follows. The out of sample accuracy rate is expected to be 0.91. The relationship between number of trees and error rates are plotted.

```{r cross_validation}
confusionMatrix(tst_train_usr_win_mean$classe,predict(modFit,tst_train_usr_win_mean[,-53]))

```

## Prediction

```{r prediction}
# Prediction on real testing data set.
final_results<-predict(modFit,quizdata[,-53])
final_results
```